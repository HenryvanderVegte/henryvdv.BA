\chapter{Introduction}
\label{sec:Introduction}

\section{Background}

In the last decades, the amount of textual information in media has increased severely, making automatic text comprehension indispensable. Since textual data found online is mostly unstructured, which means that there is no formal structure in pre-defined manner, various information needs to be added in order to make automatic understanding possible. For several natural language processing (NLP) tasks, referential relationships between words in a document need to be set. For instance, in the following sentence the pronouns \textit{he} and \textit{him} refer to previously mentioned entities in the text:

\begin{center}
Peter took John's car. He is now angry with him.
\end{center}

A noun that does not have a specified meaning and can only be interpreted through its referential relation (such as \textit{he} or \textit{him}) is called \textbf{anaphora} \citep{recasens2007anaphora}. The most recent preceding noun or noun phrase\footnote{A noun phrase is a group of words ``revolving around a head noun" \citep{jurafsky2014speech}} regarding to the same real-world entity can be seen as the point of reference and is therefore termed \textbf{antecedent}. There might be cases in which the reference does not occur before, but after the considered expression (for instance, in ``before \text{he} went to bed, John ate breakfast"). Those occurrences are named \textbf{cataphora}, but will not be considered in this work due to their sparsity. The process of determining the antecedent for a considered anaphora is named \textbf{anaphora resolution}. The previous example with resolved anaphoras is shown in Figure \ref{figure:visofanaphora}.

\begin{figure}[h]
	\centering\sffamily
%\setlength{\fboxsep}{5pt}%
	\fbox{
\xytext{
  \xybarnode{\fbox{Peter}} &~&
  \xybarnode{took} &~&
  \xybarnode{\fbox{John's}} &~&
  \xybarnode{car} &~&
  \xybarnode{.} &~&
  \xybarnode{\fbox{He}}
\xybarconnect[5](U,U){-6}
 &~&
  \xybarnode{is} &~&
  \xybarnode{now} &~&
  \xybarnode{angry} &~&
  \xybarnode{with} &~&
  \xybarnode{\fbox{him}} 
\xybarconnect[8](U,U){-20}
&~&
  \xybarnode{.}
}
}
	\caption{Visualization of anaphora resolution}
	\label{figure:visofanaphora}
\end{figure}

Anaphora resolution can be considered as a subtask of \textbf{coreference resolution} as the latter aims for linking all occurrences of a real-world entity in a text (Figure \ref{figure:visofcoref}). Therefore, anaphoras are a part of it. 

\begin{figure}[h]
	\centering\sffamily
%\setlength{\fboxsep}{5pt}%
	\fbox{
\xytext{
  \xybarnode{\fbox{Peter}} &~~&
  \xybarnode{is} &~~&
  \xybarnode{\fbox{the class representative}}
\xybarconnect[5](U,U){-4}
 &~~&
  \xybarnode{.}
}
}	\caption{Visualization of coreference resolution}
	\label{figure:visofcoref}
\end{figure}

Resolving noun phrases is a growing task in Natural Language Processing (NLP) and increased its relevance in the last decades to the extent that it even became a standalone subtask in the DARPA Message Understanding Conference in 1995 \citep{chinchor1995message}. The International Workshop on Semantic Evaluation (SemEval) conducted a coreference resolution task on multiple languages \citep{recasens2010semeval} emphasizing its importance. 
There are several fundamental applications of coreference and anaphora resolution, such as Information Extraction (IE) \citep{mccarthy1995using} and Question Answering (QA) \citep{morton2000coreference}.\\ 
Information Extraction targets to summarize relevant information from documents. Anaphora resolution is required as the quested entity is often referenced through various words, amongst others personal pronouns. \cite{mccarthy1995using} described the latter as a classification problem: ``Given two references, do they refer to the same object or different objects."\\
The question answering task described by Morton seeks to find a 250 byte string excerpt out of a number of documents as the answer for a query. Annotated coreference chains were used to link all instances of the same entity in a document. Occurrences in another sentence are given a lower weight for prediction. The use of annotated coreference chains improved the prediction slightly.\\
Various information sources, including syntactic, semantic, and pragmatic knowledge are needed since selecting a possible antecedent is a decision under high ambiguity. The decisive factor for determination might be e.g. gender agreement or the distance between antecedent and anaphora. For instance, in Figure \ref{figure:mascmatch} the contextual information is used that \textit{John} is commonly a masculine first name and will therefore refer to \textit{he}.
\begin{figure}[h]
%\setlength{\fboxsep}{5pt}%
\centering\sffamily
	\fbox{
\xytext{
  \xybarnode{\fbox{John}} &~&
  \xybarnode{and} &~&
  \xybarnode{Jill} &~&
  \xybarnode{had} &~&
  \xybarnode{a}&~&
  \xybarnode{date} &~&
  \xybarnode{,} &~&
  \xybarnode{but} &~&
  \xybarnode{\fbox{he}} 
\xybarconnect[5](U,U){-16}
&~&
  \xybarnode{didn't} &~&
  \xybarnode{come} &~&
  \xybarnode{.}
}
}
\caption{Masculine gender match}
	\label{figure:mascmatch}
\end{figure}

In contrast to that, the female pronoun \textit{she} in Figure \ref{figure:femmatch} will most likely refer to \textit{Jill}.


\begin{figure}[h]
%\setlength{\fboxsep}{5pt}%
\centering\sffamily
	\fbox{
\xytext{
  \xybarnode{John} &~&
  \xybarnode{and} &~&
  \xybarnode{\fbox{Jill}} &~&
  \xybarnode{had} &~&
  \xybarnode{a}&~&
  \xybarnode{date} &~&
  \xybarnode{,} &~&
  \xybarnode{but} &~&
  \xybarnode{\fbox{she}} 
\xybarconnect[5](U,U){-12}
&~&
  \xybarnode{didn't} &~&
  \xybarnode{come} &~&
  \xybarnode{.}
}
}
\caption{Feminine gender match}
	\label{figure:femmatch}
\end{figure}

%Cataphora 
%Pleonastic it

\section{Motivation}
\label{introductionMotivation}
Significant factors of uncertainty are gender and number, because they are hard to determine. At first, information is needed whether a noun is male, female, neutral, or plural.\footnote{In the following work plural will be also considered as gender since it occurs as a seperate category, especially if pronouns are observed.} Honorifics like ``Mr." and ``Mrs." are gender indicators, but not sufficient due to their sparsity. Stereotypical occupations and gender indicating suffixes like policeman and policewoman turned out to be no longer reliable \citep{evans2000improving}. For that reason, gender and number information needs to be learned from an external source. 

There are two different strategies for implementing reliable gender information: \\
Firstly, gender can be treated as a hard constraint. This means that either the most likely gender is assigned or, in case of uncertainty, no assignment is made at all. The leading coreference resolution systems mostly use hard constraint gender information \citep{soon2001machine}. The gender of to the most frequent sense of a noun is assumed.\\
Secondly, gender can be expressed through probabilities. If a noun is male in 70 of 100 cases, the probability for it to be male is 70 \% (note that this is simplified - those distribution will mostly be smoothed to avoid 0-probabilities). \cite{bergsma2005automatic} reported an increase of accuracy due to this implementation method.

This work will present a machine learning approach to anaphora resolution, focusing on third-person pronominal anaphoras. The two main purposes are to determine the impact of gender probability and to compare it to gender information treated as a hard constraint. First of all, it should be evaluated whether the improvement through gender frequencies \cite{bergsma2005automatic} reported can be replicated on different data. In a second step, the gender frequencies will be replaced by the assignment of the most frequent gender to examine the influence of nothing but the gender implementation strategy. This is necessary as usage of different data sets and algorithms makes the comparison of papers inconclusive. Finally, it needs to be examined whether the hypothesis that corpus based gender frequencies have a higher impact than gender constraints can be confirmed.

